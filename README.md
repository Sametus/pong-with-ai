# ğŸ“ RL Pong (DQN) Â· Pygame + Keras

[![Python](https://img.shields.io/badge/Python-3.8%E2%80%933.10-blue.svg)](https://python.org)
[![TensorFlow](https://img.shields.io/badge/TensorFlow-2.10%E2%80%932.14-orange.svg)](https://tensorflow.org)
[![Pygame](https://img.shields.io/badge/Pygame-2.1%2B-green.svg)](https://pygame.org)

> Basit bir Pong benzeri ortamda iki ajanla Deep Q-Learning (DQN) eÄŸitimi.

Kod Ã¶ÄŸretici/deneysel amaÃ§lÄ±dÄ±r; ÅŸimdilik baÅŸarÄ± seviyesi sÄ±nÄ±rlÄ±dÄ±r. GeliÅŸtirmeye tamamen aÃ§Ä±k ve farklÄ± sÃ¼rÃ¼mleri planlanmaktadÄ±r.

> âš ï¸ **Not:** Depo boyutu/daÄŸÄ±tÄ±m kÄ±sÄ±tlarÄ± nedeniyle uzun eÄŸitim (Ã§ok episode) sonucu oluÅŸan bÃ¼yÃ¼k model dosyalarÄ± repoda yer almÄ±yor. Checkpoint mantÄ±ÄŸÄ± mevcut; kendi eÄŸitimlerinizle devam edebilirsiniz.

---
![pong_with_ai.gif](pong_with_ai.gif)
---

## âœ¨ Ã–zellikler

- ğŸ® **Pygame tabanlÄ± minimal Pong ortamÄ±** (sol & saÄŸ ped + top)
- ğŸ§  **KÃ¼Ã§Ã¼k MLP + LeakyReLU aktivasyon**
- âš¡ **VektÃ¶rize Replay** (tek fit, birkaÃ§ predict)
- ğŸ’¾ **Checkpoint + Resume:**
  - Model aÄŸÄ±rlÄ±klarÄ± ve optimizer durumu (`.keras`)
  - Ajan durumu (epsilon + replay buffer) (`.state.gz`)
- ğŸ–¥ï¸ **GPU opsiyonel** (kÃ¼Ã§Ã¼k aÄŸlarda CPU daha akÄ±cÄ± olabilir)

---

## ğŸ“‹ Gereksinimler
Projeyle test edilmiÅŸ Ã¶rnek sÃ¼rÃ¼mler:
- **Python** 3.7
- **TensorFlow** 2.10â€“2.14 (Keras dÃ¢hil)
- **pygame** 2.1+
- **numpy** 1.23+

### ğŸš€ HÄ±zlÄ± kurulum (conda)

```bash
conda create -n rl_codes python=3.9 -y
conda activate rl_codes
pip install "tensorflow==2.12.*" pygame==2.1.2 numpy==1.24.*
```

> ğŸ’¡ **Not:** KÃ¼Ã§Ã¼k aÄŸlarda pencere takÄ±lmasÄ± gÃ¶rÃ¼rseniz GPU'yu kapatÄ±p CPU'da Ã§alÄ±ÅŸtÄ±rÄ±n (TF importundan Ã¶nce):
> ```python
> import os
> os.environ["CUDA_VISIBLE_DEVICES"] = "-1"
> ```

---

## ğŸ¯ Ã‡alÄ±ÅŸtÄ±rma
Proje tek dosyadÄ±r (Ã¶rn. main.py). Ã‡alÄ±ÅŸtÄ±rÄ±n:

```bash
python main.py
```

- `models/` dizininde Ã¶nceden checkpoint varsa otomatik kaldÄ±ÄŸÄ± yerden devam eder
- Yoksa 1. bÃ¶lÃ¼mden baÅŸlar
- VarsayÄ±lan olarak her 50 bÃ¶lÃ¼mde checkpoint alÄ±nÄ±r (model + ajan durumu)

### ğŸ’¾ Checkpoint biÃ§imi

- **Model:** `models/agent1_ep{N}.keras`, `models/agent2_ep{N}.keras`
  - (aÄŸÄ±rlÄ±k + optimizer state â†’ gerÃ§ek resume)
- **Ajan durumu:** `models/agent{X}_ep{N}.state.gz`
  - (epsilon + replay buffer)

**LeakyReLU ile yÃ¼kleme (Ã¶rnek):**
```python
from tensorflow.keras.layers import LeakyReLU
model = load_model("models/agent1_ep150.keras",
                   custom_objects={"LeakyReLU": LeakyReLU})
```

---

## ğŸ® Oynatma (Play) Modu
EÄŸitim yerine sadece oynamak istiyorsanÄ±z, eÄŸitilmiÅŸ modelleri yÃ¼kleyip aksiyonlarÄ± `argmax(Q)` ile seÃ§en kÄ±sa bir dÃ¶ngÃ¼ ekleyebilirsiniz.

> âš ï¸ **Ã–nemli:** `getCoordinate()` eÄŸitimle aynÄ± olmalÄ± (bu projede `(rect.x, rect.y)`).

> ğŸ’¡ **Ä°pucu:** EÄŸitimde kullandÄ±ÄŸÄ±nÄ±z FPS ile Play FPS aynÄ± olsun; aksi halde dinamikler deÄŸiÅŸir.

---

## ğŸ—ï¸ Proje YapÄ±sÄ± (Ã¶zet)

- **Tick / Ball / Env:** Pygame sprite'larÄ± ve ortam
- **DQLAgent:**
  - `build_model()`: 32-32 MLP + LeakyReLU
  - `remember()`, `act()`
  - `replay()`: vektÃ¶rize DQN gÃ¼ncellemesi
  - `adaptiveEGreedy()`: epsilon azaltÄ±mÄ±
- **Checkpoint:** `.keras` + `.state.gz` (atomik yazÄ±m)
- **Resume:** En gÃ¼ncel ortak episode otomatik bulunur

---

## âš ï¸ Bilinen SÄ±nÄ±rlamalar
- ğŸ¯ Kod bilinÃ§li olarak basit tutuldu; "gerÃ§ek Pong" fiziÄŸi yok
- ğŸ“ˆ BaÅŸarÄ± seviyesi ÅŸu an yeterli deÄŸil; daha uzun eÄŸitim ve/veya Ã¶dÃ¼l/mimari iyileÅŸtirmeleri gerekiyor
- ğŸ’¾ Uzun eÄŸitim sonucu oluÅŸan bÃ¼yÃ¼k modeller repoya dÃ¢hil edilmedi (dosya boyutu ve kaynak kÄ±sÄ±tlarÄ±)

---

## ğŸ—ºï¸ Yol HaritasÄ± / KatkÄ±

### Planlanan/Ã¶nerilen geliÅŸtirmeler:

- ğŸ¯ **Target Network (DDQN)**
- ğŸ“Š **Prioritized Replay**
- ğŸ† **Ã–dÃ¼l shaping** (temas +r, yÃ¶nlÃ¼ bonus vs.)
- âš™ï¸ **Fizikte deterministikleÅŸtirme** ve tÃ¼nelleme Ã¶nleme iyileÅŸtirmeleri
- ğŸ¤– **Tek ajan vs. scripted/heuristic rakip** (Ã¶ÄŸrenmeyi kolaylaÅŸtÄ±rÄ±r)
- ğŸ” **Parametre taramalarÄ±** (LR, epsilon planÄ±, batch size, LeakyReLU alpha)
- ğŸ“ˆ **Loglama/plot** (Ã¶r. TensorBoard, matplotlib)

> ğŸ¤ **PR ve Ã¶nerilere aÃ§Ä±ÄŸÄ±z.** Sorun/iyileÅŸtirme iÃ§in lÃ¼tfen Issue aÃ§Ä±n.

---

## ğŸ“„ Lisans

**MIT** (veya dilediÄŸiniz lisansÄ± belirtin)

---

## ğŸ™ TeÅŸekkÃ¼r

Bu Ã§alÄ±ÅŸma, Ã¶ÄŸrenme/deney amaÃ§lÄ± minimal bir DQN iskeleti sunmayÄ± hedefler. Geri bildirim ve katkÄ±larÄ±nÄ±z projeyi daha iyi hÃ¢le getirecek.


---
